#!/bin/bash
set -eu

JOB=kubelet
BIN=kubelet
SIGTERM_FOR=15
SIGKILL_FOR=5

RUN_DIR=/var/vcap/sys/run/$JOB
LOG_DIR=/var/vcap/sys/log/$JOB
JOB_DIR=/var/vcap/jobs/$JOB
CERTS_DIR=/var/vcap/data/k8s/certs
DAT_DIR=/var/vcap/data/k8s/$JOB
PIDFILE=$RUN_DIR/$BIN.pid
exec >>$LOG_DIR/$BIN.log 2>&1

<%

def slugify(s)
  return s.gsub('(deployment)', spec.deployment)
          .gsub('(name)',       spec.name)
          .gsub('(id)',         spec.id)
end

labels = p('labels', [])
taints = p('taints', {})

if p('master')
  taints.push('node-role.kubernetes.io/master=true:NoSchedule')
end

%>

# set kube-* binaries in our path
export PATH=$PATH:/var/vcap/packages/k8s/bin
export PATH=$PATH:/var/vcap/packages/jq/bin

case $1 in
  start)
    mkdir -p $RUN_DIR

    # FIXME: wait for containerd to be up and running

    echo "[$(date)] $BIN/$$: starting up..."

    if [[ -f $PIDFILE ]]; then
      PID=$(head -1 $PIDFILE)
      if [[ -n "$PID" ]]; then
        if [[ -e /proc/$PID ]]; then
          echo "[$(date)] $BIN/$$: found pid file $PIDFILE, with pid '$PID' (which is running)"
          exit 1
        fi
        echo "[$(date)] $BIN/$$: found (stale) pid file $PIDFILE, with pid '$PID' (which is defunct)"
      fi
      rm -f $PIDFILE
    fi
    kill -9 $(pgrep kubelet | grep -v $$) || true

    echo "[$(date)] $BIN/$$: turning off swap..."
    swapoff -a
    free
    echo

    echo "[$(date)] $BIN/$$: refreshing our kubeconfig..."
    mkdir -p $DAT_DIR
    rm -f $DAT_DIR/kubeconfig # legacy
    rm -f $DAT_DIR/automaton.kubeconfig
    rm -f $DAT_DIR/kubelet.kubeconfig
    kubectl config set-cluster <%= link('api').p('cluster.name') %> \
        --certificate-authority=$JOB_DIR/tls/ca/cert.pem \
        --embed-certs=true \
        --server=https://<%= p('apiserver') %> \
        --kubeconfig=$DAT_DIR/kubelet.kubeconfig
    kubectl config set-credentials system:nodes:node \
        --client-certificate=$CERTS_DIR/kubelet/cert.pem \
        --client-key=$CERTS_DIR/kubelet/key.pem \
        --embed-certs=true \
        --kubeconfig=$DAT_DIR/kubelet.kubeconfig
    kubectl config set-context default \
        --cluster=<%= link('api').p('cluster.name') %> \
        --user=system:nodes:node \
        --kubeconfig=$DAT_DIR/kubelet.kubeconfig
    kubectl config use-context default --kubeconfig=$DAT_DIR/kubelet.kubeconfig
    echo

    NODENAME="<%= spec.id %>.k8s"
    echo "[$(date)] $BIN/$$: setting hostname to $NODENAME..."
    hostname $NODENAME

    PROVIDER_ID=
    if grep -q vsphere /var/vcap/bosh/etc/infrastructure; then
      PROVIDER_ID=$(tr A-Z a-z < /sys/class/dmi/id/product_uuid)
      echo "[$(date)] $BIN/$$: it looks like this is vsphere; detected providerID is '$PROVIDER_ID'"
    fi

    KUBELET_OPTIONS=
    if [[ -n $PROVIDER_ID ]]; then
      KUBELET_OPTIONS="$KUBELET_OPTIONS --provider-id=$PROVIDER_ID"
    fi

    echo "[$(date)] $BIN/$$: setting up our automaton kubeconfig (for updating node providerIDs)..."
    kubectl config set-cluster <%= link('api').p('cluster.name') %> \
        --certificate-authority=$JOB_DIR/tls/ca/cert.pem \
        --embed-certs=true \
        --server=https://<%= p('apiserver') %> \
        --kubeconfig=$DAT_DIR/automaton.kubeconfig
    kubectl config set-credentials automaton \
        --client-certificate=$CERTS_DIR/automaton/cert.pem \
        --client-key=$CERTS_DIR/automaton/key.pem \
        --embed-certs=true \
        --kubeconfig=$DAT_DIR/automaton.kubeconfig
    kubectl config set-context default \
        --cluster=<%= link('api').p('cluster.name') %> \
        --user=automaton \
        --kubeconfig=$DAT_DIR/automaton.kubeconfig
    kubectl config use-context default --kubeconfig=$DAT_DIR/automaton.kubeconfig
    export KUBECONFIG=$DAT_DIR/automaton.kubeconfig
    echo

    if test -n $PROVIDER_ID && kubectl get node $NODENAME >/dev/null 2>&1; then
      OLD_PROVIDER_ID=$(kubectl get node $NODENAME -o jsonpath --template '{.spec.providerID}')
      if [[ $PROVIDER_ID != $OLD_PROVIDER_ID ]]; then
        echo "[$(date)] $BIN/$$: node $NODENAME providerID changed from $OLD_PROVIDER_ID -> $PROVIDER_ID; deleting node..."
        kubectl delete node $NODENAME
      fi
    fi

    echo "[$(date)] $BIN/$$: starting up kubelet..."
    echo $$ > $PIDFILE
    exec kubelet <% labels.each do |label, value| %>--node-labels "<%= slugify(label) %>=<%= slugify(value) %>" <% end %>\
           --config=$JOB_DIR/etc/kubelet.yml \
           --container-runtime=remote \
           --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \
           --image-pull-progress-deadline=2m \
           --kubeconfig=$DAT_DIR/kubelet.kubeconfig \
           --network-plugin=cni \
           --register-node=true \
           --register-with-taints=<%= taints.join(',') %> \
           --hostname-override=<%= spec.id %>.k8s \
           --root-dir=/var/vcap/store/kubelet/ \
           <% if link('cloud-provider').p('cloud-provider.type', '') != '' %>--cloud-provider=<%= link('cloud-provider').p('cloud-provider.type') %> --cloud-config=/var/vcap/jobs/kubelet/etc/cloud-config <% end %>\
           $KUBELET_OPTIONS \
           --v=2 <% p('kubelet.flags', []).each do |kv| %><% kv.each do |flag,value| %>--<%= flag %>="<%= value.to_s.gsub(/"/, '\\"') %>" <% end %><% end %>
    echo "[$(date)] $BIN/$$: exec failed!"
    exit 42
    ;;


  stop)
    echo "[$(date)] $BIN/$$: shutting down..."
    if [[ -f $PIDFILE ]]; then
      PID=$(head -1 $PIDFILE)
      if [[ -n "$PID" ]]; then
        if [[ -e /proc/$PID ]]; then
          echo "[$(date)] $BIN/$$: found pid file $PIDFILE, with pid '$PID' (which is running)"
          echo "[$(date)] $BIN/$$: sending SIGTERM for ${SIGTERM_FOR}s, followed by a SIGKILL..."
          for i in $(seq 1 $(expr $SIGTERM_FOR \* 10)); do
            kill -TERM $PID || true
            if [[ ! -e /proc/$PID ]]; then
              echo "[$(date)] $BIN/$$: pid $PID terminated (via SIGTERM)"
              rm -f $PIDFILE
              echo "[$(date)] $BIN/$$: shut down complete"
              exit 0
            fi
            sleep 0.1
          done

          echo "[$(date)] $BIN/$$: pid $PID did not termiante (via SIGTERM) within ${SIGTERM_FOR}s; sending a SIGKILL and waiting ${SIGKILL_FOR}s..."
          for i in $(seq 1 $(expr $SIGKILL_FOR \* 10)); do
            kill -KILL $PID || true
            if [[ ! -e /proc/$PID ]]; then
              echo "[$(date)] $BIN/$$: pid $PID terminated (via SIGKILL)"
              rm -f $PIDFILE
              echo "[$(date)] $BIN/$$: shut down complete"
              exit 0
            fi
            sleep 0.1
          done
          echo "[$(date)] $BIN/$$: pid $PID did not termiante (via SIGKILL) within ${SIGKILL_FOR}s; giving up."
          exit 1
        fi

        echo "[$(date)] $BIN/$$: found (stale) pid file $PIDFILE, with pid '$PID' (which is defunct)"
      fi
      rm -f $PIDFILE
    fi
    echo "[$(date)] $BIN/$$: shut down complete"
    exit 0
    ;;
esac
